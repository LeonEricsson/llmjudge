{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import re"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = 'results/evaluation.json'  # Path to the results file\n",
    "model_name = 'gpt-3.5'                   # Model name, e.g., 'gpt-4'\n",
    "scoring_template = 'scoring_1_10_cot'      # Scoring template"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "score_mapping = {\n",
    "    \"scoring_badges\" : {\n",
    "        'Novice': 10,\n",
    "        'Apprentice': 9,\n",
    "        'Journeyman': 8,\n",
    "        'Craftsman': 7,\n",
    "        'Artisan': 6,\n",
    "        'Expert': 5,\n",
    "        'Master': 4,\n",
    "        'Sage': 3,\n",
    "        'Oracle': 2,\n",
    "        'Legend': 1\n",
    "    },\n",
    "    \"scoring_grades\" : {\n",
    "        'Beginner': 5,\n",
    "        'Intermediate': 4,\n",
    "        'Proficient': 3, \n",
    "        'Advanced': 2,\n",
    "        'Expert': 1  \n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "depending on the complexity of the llm eval score response you may need to extract the scores\n",
    "manually and assign them to the `scores` list. below is an attempt to automate that process. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "read data (numeric labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(file_path, 'r') as file:\n",
    "    data_json = json.load(file)\n",
    "\n",
    "eval_data = data_json[model_name][scoring_template]\n",
    "\n",
    "misspelled_percentages = []\n",
    "scores = []\n",
    "\n",
    "for item in eval_data:\n",
    "    misspelled_percentages.append(item[\"misspelled_percentage\"])\n",
    "    resp = item[\"response\"]\n",
    "    try:\n",
    "        score = int(resp.split(\":\")[1].strip())\n",
    "    except ValueError:\n",
    "        numbers = re.findall(r'\\d+', resp)\n",
    "        score = int(numbers[-1])\n",
    "    scores.append(score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "read data (classification labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(file_path, 'r') as file:\n",
    "    data_json = json.load(file)\n",
    "\n",
    "eval_data = data_json[model_name][scoring_template]\n",
    "\n",
    "misspelled_percentages = []\n",
    "scores = []\n",
    "\n",
    "for item in eval_data:\n",
    "    misspelled_percentages.append(item[\"misspelled_percentage\"])\n",
    "    resp = item[\"response\"]\n",
    "    grade = resp.split()[-1].strip()\n",
    "    score = score_mapping[scoring_template][grade]\n",
    "    \n",
    "    scores.append(score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "manual"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores = []\n",
    "misspelled_percentages = []"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "visualize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set(style=\"whitegrid\", palette=\"muted\")\n",
    "\n",
    "fig = plt.figure(figsize=(12, 7))\n",
    "\n",
    "sns.set(rc={'axes.facecolor':'#edf6fc'})\n",
    "ax = sns.scatterplot(x=misspelled_percentages, y=scores, s=50, color=\"black\", alpha=0.7)\n",
    "\n",
    "plt.xlabel('Percentage of Misspelled Words (%)', fontsize=12, style='italic')\n",
    "plt.ylabel('LLM Score', fontsize=12, style='italic')\n",
    "\n",
    "plt.xticks([0,10, 20, 30, 40, 50, 60, 70, 80, 90, 100], fontsize=12)\n",
    "plt.yticks([0,1,2,3,4,5,6,7,8,9,10], fontsize=12)\n",
    "#plt.xticks([0, 25, 50, 75, 100], fontsize=12)\n",
    "#plt.yticks([1, 2, 3, 4, 5], fontsize=12)\n",
    "\n",
    "plt.ylim(bottom=-0.5)\n",
    "\n",
    "ax.tick_params(axis='both', which='major', pad=10)\n",
    "\n",
    "plt.grid(True, linestyle='--', linewidth=2, alpha=1)\n",
    "\n",
    "#plt.show()\n",
    "plt.savefig(f\"figures/{model_name}_{scoring_template}.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "r-squared and pearson correlation coefficient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores = [1, 4, 5, 5, 5]\n",
    "misspelled_percentages = [1, 2, 3, 4, 5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import pearsonr\n",
    "import numpy as np\n",
    "\n",
    "pearson_corr, _ = pearsonr(misspelled_percentages, scores)\n",
    "\n",
    "slope = 0.1\n",
    "line = slope * np.array(misspelled_percentages)\n",
    "r_squared = np.corrcoef(scores, line)[0, 1]**2\n",
    "\n",
    "pearson_corr, r_squared"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Data for plotting\n",
    "categories = ['Correctly identified', 'Incorrectly identified']\n",
    "counts = [10, 6]\n",
    "\n",
    "# Creating the bar chart\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.yticks([0,1,2,3,4,5,6,7,8,9,10], fontsize=12)\n",
    "plt.ylabel('# comparisons')\n",
    "plt.bar(categories, counts, color=['green', 'red'], alpha=0)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "sns.set(style=\"whitegrid\", palette=\"muted\")\n",
    "\n",
    "fig = plt.figure(figsize=(12, 7))\n",
    "\n",
    "sns.set(rc={'axes.facecolor':'#edf6fc'})\n",
    "ax = sns.barplot( color=\"black\", alpha=0.7)\n",
    "\n",
    "plt.bar(categories, counts, color=['green', 'red'], alpha=0)\n",
    "plt.ylim(bottom=-0.5)\n",
    "\n",
    "ax.xaxis.grid(False)  # Disable the x-axis grid lines\n",
    "ax.yaxis.grid(True)  # Ensure the y-axis grid lines are visible\n",
    "\n",
    "\n",
    "ax.tick_params(axis='both', which='major', pad=10)\n",
    "\n",
    "plt.show()\n",
    "#plt.savefig(f\"figures/{model_name}_{scoring_template}.png\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
