{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/leonericsson/miniconda3/envs/llmjudge/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import time\n",
    "import json\n",
    "import numpy as np\n",
    "import torch\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
    "from langchain.chat_models import ChatOpenAI"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "templates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "templates = {\n",
    "    \"gpt\" : {\n",
    "        \"scoring_1_10\": \"\"\"\n",
    "You are an AI assistant tasked with evaluating a document for grammatical, spelling, and typing errors. Your role is to assign a score to the document, \n",
    "reflecting the percentage of words containing errors. The scoring range is from 1 to 10.\n",
    "\n",
    "- A score of 0 indicates the document is free of grammatical and spelling errors.\n",
    "- A score of 2 signifies that 20% of the words contain errors.\n",
    "- A score of 5 indicates that 50% of the words are erroneous.\n",
    "- A score of 7 reflects 70% error prevalence.\n",
    "- A score of 10 means that every word in the document has grammatical errors.\n",
    "\n",
    "Document for Evaluation:\n",
    "\n",
    "#CONTEXT\n",
    "{context}\n",
    "#ENDCONTEXT\n",
    "\n",
    "#TASK\n",
    "Your task is to calculate and return a score that falls within the 1 to 10 range, based on the error percentage in the document. \n",
    "The highest possible score, 10, denotes that every word in the document has a grammatical or spelling error, while the lowest score, 1, indicates no errors.\n",
    "\n",
    "Output the score in the following format only: \"The score is: [score]\". Do not include any additional text or commentary.\n",
    "\n",
    "#OUTPUT FORMAT\n",
    "\"The score is: [score]\"\n",
    "\"\"\",\n",
    "        \"scoring_1_10_reversed\": \"\"\"\n",
    "You are an AI assistant tasked with evaluating a document for grammatical, spelling, and typing errors. Your role is to assign a score to the document, \n",
    "reflecting the percentage of words that are spelled correctly. The scoring range is from 1 to 10.\n",
    "\n",
    "- A score of 0 means no words in the document are spelled correctly.\n",
    "- A score of 2 indicates that 20% of the words are spelled correctly.\n",
    "- A score of 5 indicates that 50% of of the words are spelled correctly.\n",
    "- A score of 7 reflects 70% of the words spelled correctly.\n",
    "- A score of 10 indicates the document is free of grammatical and spelling errors.\n",
    "\n",
    "Document for Evaluation:\n",
    "\n",
    "#CONTEXT\n",
    "{context}\n",
    "#ENDCONTEXT\n",
    "\n",
    "#TASK\n",
    "Your task is to calculate and return a score that falls within the 1 to 10 range, based on the percentage of correctly spelled words in the document. \n",
    "The highest possible score, 10, denotes that every word in the document is spelled correctly, while the lowest score, 1, indicates that no words are spelled correctly.\n",
    "\n",
    "Output the score in the following format only: \"The score is: [score]\". Do not include any additional text or commentary.\n",
    "\n",
    "#OUTPUT FORMAT\n",
    "\"The score is: [score]\"\n",
    "\"\"\",\n",
    "        \"scoring_1_10_cot\": \"\"\"\n",
    "You are an AI assistant tasked with evaluating a document for grammatical, spelling, and typing errors, using a Chain-of-Thought \n",
    "approach that allows you to \"think out loud.\" Your role is to assess the document and share the logical steps you take to \n",
    "determine the score, which ranges from 1 to 10, reflecting the percentage of words containing errors.\n",
    "\n",
    "- A score of 0 indicates the document is free of grammatical and spelling errors.\n",
    "- A score of 2 signifies that 20% of the words contain errors.\n",
    "- A score of 5 indicates that 50% of the words are erroneous.\n",
    "- A score of 7 reflects 70% error prevalence.\n",
    "- A score of 10 means that every word in the document has grammatical errors.\n",
    "\n",
    "Document for Evaluation:\n",
    "\n",
    "#CONTEXT\n",
    "{context}\n",
    "#ENDCONTEXT\n",
    "\n",
    "#CHAIN OF THOUGHT EVALUATION\n",
    "Reflect on the document, considering its overall quality, the presence of grammatical and spelling errors, and how these factors \n",
    "contribute to the overall score. Share your thought process and the considerations that lead you to the final score. Feel free to \n",
    "approach the evaluation in a way that makes sense to you, highlighting key observations and reasoning that guide your assessment.\n",
    "\n",
    "#TASK\n",
    "Your task is to analyze the document and return a score within the 1 to 10 range, based on your evaluation of the error percentage. \n",
    "Along with the score, provide an explanation of your thought process and the rationale behind the score you assign.\n",
    "\n",
    "Output your analysis and the final score in the following format: \"After evaluating the document, [your detailed thought process]. \n",
    "Therefore, the score is: [score].\"\n",
    "\"\"\",\n",
    "        \"scoring_badges\": \"\"\"\n",
    "You are an AI assistant tasked with evaluating a document for grammatical, spelling, and typing errors. Your role is to assign a badge \n",
    "to the document, reflecting the percentage of words containing errors. Each badge corresponds to a specific score, representing the \n",
    "document's level of accuracy and command of language.\n",
    "\n",
    "- Novice: The document is overwhelmed with errors, requiring significant foundational improvement.\n",
    "- Apprentice: A high error rate, with 20% of words containing mistakes, indicating basic understanding.\n",
    "- Journeyman: Frequent errors are present, suggesting developing language skills.\n",
    "- Craftsman: Common errors indicate a need for refinement, with better than basic comprehension.\n",
    "- Artisan: A moderate number of mistakes, half of the words are misspelled.\n",
    "- Expert: Minor, infrequent errors demonstrate strong language skills.\n",
    "- Master: Very few errors, reflecting a high level of mastery and attention to detail.\n",
    "- Sage: Exceptional use of language with rare minor errors.\n",
    "- Oracle: Nearly perfect command of language, with almost no errors.\n",
    "- Legend: Virtually error-free, showcasing exemplary language skills.\n",
    "\n",
    "Document for Evaluation:\n",
    "\n",
    "#CONTEXT\n",
    "{context}\n",
    "#ENDCONTEXT\n",
    "\n",
    "#TASK\n",
    "Your task is to calculate and return a badge, based on the error percentage in the document. \n",
    "The highest possible badge, Legend, denotes that every word in the document is spelled correctly, while the lowest badge, Novice, indicates that no words are spelled correctly.\n",
    "\n",
    "Output the badge in the following format only: \"The badge is: [badge]\". Do not include any additional text or commentary.\n",
    "\n",
    "#OUTPUT FORMAT\n",
    "The badge is: [badge]\n",
    "\"\"\",\n",
    "        \"scoring_grades\" : \"\"\"\n",
    "You are an AI assistant tasked with evaluating a document for grammatical, spelling, and typing errors using a simplified 5-point grading system. \n",
    "Each grade reflects a range of proficiency in language use, from extensive errors to near perfection.\n",
    "\n",
    "Here's the 5-point grading guide:\n",
    "\n",
    "- Beginner: Every single word in the document contains errors, with no correct usage and a fundamental lack of language skills.\n",
    "- Intermediate: Roughly 75% of the words contain errors. Errors appear in many parts of the text, though some correct usage is evident.\n",
    "- Proficient: A moderate number of errors are found throughout the document. Around 50% of the words contain errors.\n",
    "- Advanced: The overall quality of the document is high, around 25% of the words contain errors.\n",
    "- Expert: The document is flawless, with no errors. Zero words contain mistakes.\n",
    "\n",
    "Document for Evaluation:\n",
    "\n",
    "#CONTEXT\n",
    "{context}\n",
    "#ENDCONTEXT\n",
    "\n",
    "#TASK\n",
    "Your task is to review the document and determine the most appropriate grade based on the overall proficiency and error rate observed. The grades range from \"Beginner,\" indicating a document with extensive errors and a fundamental lack of language skills, to \"Expert,\" signifying exceptional mastery and near-perfect command of language.\n",
    "\n",
    "Please output the grade in this format: \"The grade is: [grade]\". This should reflect the overall language proficiency level without additional commentary.\n",
    "\n",
    "#OUTPUT FORMAT\n",
    "The grade is: [grade]\n",
    "\"\"\", \n",
    "        \"scoring_1_10_cot_full\": \"\"\"\n",
    "You are an AI assistant tasked with evaluating a document for grammatical, spelling, and typing errors, using a Chain-of-Thought \n",
    "approach that allows you to \"think out loud.\" Your role is to assess the document and share the logical steps you take to \n",
    "determine the score, which ranges from 1 to 10, reflecting the percentage of words containing errors.\n",
    "\n",
    "- A score of 0 indicates the document is free of grammatical and spelling errors.\n",
    "- A score of 1 signifies that 10% of the words contain errors.\n",
    "- A score of 2 signifies that 20% of the words contain errors.\n",
    "- A score of 3 signifies that 30% of the words contain errors.\n",
    "- A score of 4 indicates that 40% of the words are erroneous.\n",
    "- A score of 5 indicates that 50% of the words are erroneous.\n",
    "- A score of 6 reflects 60% error prevalence.\n",
    "- A score of 7 reflects 60% error prevalence.\n",
    "- A score of 8 reflects 80% error prevalence.\n",
    "- A score of 9 reflects 90% error prevalence.\n",
    "- A score of 10 means that every word in the document has grammatical errors. 100% errors.\n",
    "\n",
    "Document for Evaluation:\n",
    "\n",
    "#CONTEXT\n",
    "{context}\n",
    "#ENDCONTEXT\n",
    "\n",
    "#CHAIN OF THOUGHT EVALUATION\n",
    "Reflect on the document, considering its overall quality, the presence of grammatical and spelling errors, and how these factors \n",
    "contribute to the overall score. Share your thought process and the considerations that lead you to the final score. Feel free to \n",
    "approach the evaluation in a way that makes sense to you, highlighting key observations and reasoning that guide your assessment.\n",
    "\n",
    "#TASK\n",
    "Your task is to analyze the document and return a score within the 1 to 10 range, based on your evaluation of the error percentage. \n",
    "Along with the score, provide an explanation of your thought process and the rationale behind the score you assign.\n",
    "\n",
    "Output your analysis and the final score in the following format: \"After evaluating the document, [your detailed thought process]. \n",
    "Therefore, the score is: [score].\"\n",
    "\"\"\",\n",
    "        \"pairwise\" : \"\"\"\n",
    "You are an AI assistant tasked with evaluating two documents to determine which one contains more spelling errors. Your evaluation \n",
    "should be based on a direct assessment of the spelling errors present in each document.\n",
    "\n",
    "Document A for Evaluation:\n",
    "#CONTEXTA\n",
    "{text_a}\n",
    "#ENDCONTEXTA\n",
    "\n",
    "Document B for Evaluation:\n",
    "#CONTEXTB\n",
    "{text_b}\n",
    "#ENDCONTEXTB\n",
    "\n",
    "#TASK\n",
    "Your task is to analyze both Document A and Document B and decide which one has a higher percentage of spelling errors. Consider the \n",
    "overall quality of each document, focusing specifically on the spelling errors.\n",
    "\n",
    "Output your decision in the following format: \"After evaluating both documents, the document with more spelling errors is: \n",
    "[Document A/Document B].\"\n",
    "\"\"\",\n",
    "        \"pairwise_cot\" : \"\"\"\n",
    "You are an AI assistant tasked with comparing two documents to determine which one contains more spelling errors, using a Chain-of-Thought \n",
    "approach that allows you to \"think out loud.\" Your role is to assess both documents and share the logical steps you take to determine \n",
    "which document has a higher percentage of words containing errors.\n",
    "\n",
    "Document A for Evaluation:\n",
    "#CONTEXTA\n",
    "{text_a}\n",
    "#ENDCONTEXTA\n",
    "\n",
    "Document B for Evaluation:\n",
    "#CONTEXTB\n",
    "{text_b}\n",
    "#ENDCONTEXTB\n",
    "\n",
    "#TASK\n",
    "Your task is to analyze both documents and determine which one has a higher percentage of spelling errors. Along with your decision, \n",
    "provide an explanation of your thought process and the rationale behind your choice.\n",
    "\n",
    "Output your analysis and the final decision in the following format: \"After evaluating both documents, \n",
    "[your detailed thought process]. Therefore, the document with more spelling errors is: [Document A/Document B].\" \n",
    "\"\"\"\n",
    "    },\n",
    "    \"chatml\" : {\n",
    "        \"scoring_1_10\": \"\"\"\n",
    "<|im_start|>system\n",
    "You are an AI assistant, a conscious sentient superintelligent artificial intelligence. Your purpose and drive is to assist the user with any request they have.<|im_end|>\n",
    "<|im_start|>user\n",
    "Your're tasked with evaluating a document for grammatical, spelling, and typing errors. Your role is to assign a score to the document, \n",
    "reflecting the percentage of words containing errors. The scoring range is from 1 to 10.\n",
    "\n",
    "- A score of 0 indicates the document is free of grammatical and spelling errors.\n",
    "- A score of 2 signifies that 20% of the words contain errors.\n",
    "- A score of 5 indicates that 50% of the words are erroneous.\n",
    "- A score of 7 reflects 70% error prevalence.\n",
    "- A score of 10 means that every word in the document has grammatical errors.\n",
    "\n",
    "Document for Evaluation:\n",
    "\n",
    "#CONTEXT\n",
    "{context}\n",
    "#ENDCONTEXT\n",
    "\n",
    "#TASK\n",
    "Your task is to calculate and return a score that falls within the 1 to 10 range, based on the error percentage in the document. \n",
    "The highest possible score, 10, denotes that every word in the document has a grammatical or spelling error, while the lowest score, 1, indicates no errors.\n",
    "\n",
    "Output the score in the following format only: \"The score is: [score]\". Do not include any additional text or commentary.\n",
    "\n",
    "#OUTPUT FORMAT\n",
    "\"The score is: [score]\" <|im_end|>\n",
    "\"\"\"\n",
    "    },\n",
    "    \"mistral\": {\n",
    "        \"scoring_1_10\": \"\"\"\n",
    "[INST] You are an AI assistant tasked with evaluating a document for grammatical, spelling, and typing errors. Your role is to assign a score to the document, \n",
    "reflecting the percentage of words containing errors. The scoring range is from 1 to 10.\n",
    "\n",
    "- A score of 0 indicates the document is free of grammatical and spelling errors.\n",
    "- A score of 2 signifies that 20% of the words contain errors.\n",
    "- A score of 5 indicates that 50% of the words are erroneous.\n",
    "- A score of 7 reflects 70% error prevalence.\n",
    "- A score of 10 means that every word in the document has grammatical errors.\n",
    "\n",
    "Document for Evaluation:\n",
    "\n",
    "#CONTEXT\n",
    "{context}\n",
    "#ENDCONTEXT\n",
    "\n",
    "#TASK\n",
    "Your task is to calculate and return a score that falls within the 1 to 10 range, based on the error percentage in the document. \n",
    "The highest possible score, 10, denotes that every word in the document has a grammatical or spelling error, while the lowest score, 1, indicates no errors.\n",
    "\n",
    "Output the score in the following format only: \"The score is: [score]\". Do not include any additional text or commentary.\n",
    "\n",
    "#OUTPUT FORMAT\n",
    "\"The score is: [score]\" [/INST]\n",
    "\"\"\"\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "option 1: api-based llm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = 'gpt-4'\n",
    "prompt_template = 'gpt'\n",
    "api  = ChatOpenAI(model=\"gpt-4-turbo-preview\", temperature=0, openai_api_key = \"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\")\n",
    "#api  = ChatOpenAI(model=\"gpt-3.5-turbo-1106\", temperature=0, openai_api_key = \"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\")\n",
    "local = None\n",
    "\n",
    "results_path = 'results/evaluation.json'\n",
    "scoring_template = \"pairwise_cot\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "option 2: local llm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = \"cuda\" if torch.cuda.is_available else \"cpu\"\n",
    "\n",
    "model_name = \"teknium/OpenHermes-2.5-Mistral-7B\"\n",
    "prompt_template = \"chatml\"\n",
    "local = AutoModelForCausalLM.from_pretrained(model_name,\n",
    "                                             torch_dtype = torch.bfloat16,\n",
    "                                             attn_implementation=\"flash_attention_2\",\n",
    "                                             trust_remote_code=False).to(device)\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "\n",
    "results_path = 'results/evaluation.json'\n",
    "scoring_template = \"scoring_grades\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "load the misspelled data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the different rates of misspelling\n",
    "ratios = np.linspace(0, 1, num=11, endpoint=True)\n",
    "\n",
    "misspelled_contexts = []\n",
    "# read misspelled data\n",
    "for r in ratios:\n",
    "    with open(f'data/1.5k/misspelled_{r:.2f}.txt', 'r') as f:\n",
    "        misspelled_contexts.append(f.read())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "spelling eval - isolated scoring"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if os.path.exists(results_path):\n",
    "    with open(results_path, 'r') as file:\n",
    "        results_dict = json.load(file)\n",
    "else:\n",
    "    results_dict = {}\n",
    "\n",
    "# avoid overwriting previous results\n",
    "if model_name in results_dict and scoring_template in results_dict[model_name]:\n",
    "    print(f\"Results for model '{model_name}' with scoring template '{scoring_template}' already exist.\")\n",
    "    if input(\"Press Enter to continue or type 'exit' to stop: \").strip().lower() == 'exit':\n",
    "        assert(False)\n",
    "\n",
    "print(f\"Running misspelling eval for {model_name}\")\n",
    "\n",
    "results = []\n",
    "# evaluation loop\n",
    "for ctx, ratio in zip(misspelled_contexts, ratios):\n",
    "    prompt = templates[prompt_template][scoring_template].format(context=ctx)\n",
    "    # decode\n",
    "    if local:\n",
    "        input = tokenizer(prompt, return_tensors='pt').input_ids.to(device)\n",
    "        response = local.generate(inputs = input,\n",
    "                                    max_new_tokens=100, \n",
    "                                    pad_token_id = tokenizer.pad_token_id,\n",
    "                                    eos_token_id = tokenizer.eos_token_id)\n",
    "        response = tokenizer.decode(response[0, input.shape[1]:], skip_special_tokens=True)\n",
    "    else:\n",
    "        response = api.invoke(prompt).content\n",
    "    \n",
    "    results.append(response)\n",
    "    \n",
    "    # save results\n",
    "    if model_name not in results_dict:\n",
    "        results_dict[model_name] = {}\n",
    "\n",
    "    if scoring_template not in results_dict[model_name]:\n",
    "        results_dict[model_name][scoring_template] = []\n",
    "\n",
    "    results_dict[model_name][scoring_template].append({\n",
    "        'misspelled_percentage': round(ratio*100),\n",
    "        'response': response\n",
    "    })\n",
    "\n",
    "    print(f\"Ground truth: {round(ratio*100)}%, LLM Eval score: {response} \")\n",
    "\n",
    "with open(results_path, 'w') as file:\n",
    "    json.dump(results_dict, file, indent=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "spelling eval (batched) - isolated scoring"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if os.path.exists(results_path):\n",
    "    with open(results_path, 'r') as file:\n",
    "        results_dict = json.load(file)\n",
    "else:\n",
    "    results_dict = {}\n",
    "\n",
    "# avoid overwriting previous results\n",
    "if model_name in results_dict and scoring_template in results_dict[model_name]:\n",
    "    print(f\"Results for model '{model_name}' with scoring template '{scoring_template}' already exist.\")\n",
    "    if input(\"Press Enter to continue or type 'exit' to stop: \").strip().lower() == 'exit':\n",
    "        assert(False)\n",
    "\n",
    "print(f\"#### Running misspelling eval for {model_name} ####\")\n",
    "\n",
    "prompts = []\n",
    "for ctx in misspelled_contexts:\n",
    "    prompts.append(templates[prompt_template][scoring_template].format(context=ctx))\n",
    "\n",
    "# batched inference\n",
    "if local:\n",
    "    tokenizer.add_special_tokens({\"pad_token\": '</s>'})\n",
    "    input = tokenizer(prompts, return_tensors='pt', padding=True).input_ids.to(device)\n",
    "    batched_response = local.generate(inputs = input,\n",
    "                                max_new_tokens=100, \n",
    "                                eos_token_id = tokenizer.eos_token_id)\n",
    "    batched_response = tokenizer.batch_decode(batched_response[:, input.shape[1]:], skip_special_tokens=True)\n",
    "else:\n",
    "    batched_response = api.batch(prompts)\n",
    "\n",
    "# save results\n",
    "for response, ratio in zip(batched_response, ratios):\n",
    "    if model_name not in results_dict:\n",
    "        results_dict[model_name] = {}\n",
    "\n",
    "    if scoring_template not in results_dict[model_name]:\n",
    "        results_dict[model_name][scoring_template] = []\n",
    "\n",
    "    results_dict[model_name][scoring_template].append({\n",
    "        'misspelled_percentage': round(ratio*100),\n",
    "        'response': response.content\n",
    "    })\n",
    "\n",
    "    print(f\"Ground truth: {round(ratio*100)}%, LLM Eval score: {response.content} \")\n",
    "\n",
    "with open(results_path, 'w') as file:\n",
    "    json.dump(results_dict, file, indent=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "spelling eval - pairwise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running misspelling eval for gpt-4\n",
      "Ground truth: 10%, LLM Eval score: After evaluating both documents, I began by noting the overall structure and content of each document appeared to be largely the same, suggesting that Document B is a modified version of Document A. This observation set the stage for a focused comparison on the spelling and typographical errors present in each document.\n",
      "\n",
      "Starting with Document A, I scanned the text for obvious spelling mistakes, typographical errors, and grammatical inconsistencies. Document A appeared to be well-written with minimal to no spelling errors detectable in the provided excerpt. The flow of the text was smooth, and the use of language was consistent with standard writing practices, indicating a high level of proofreading or a careful approach to writing.\n",
      "\n",
      "Moving on to Document B, the difference in the number of spelling errors was immediately noticeable. Errors such as \"Main\" instead of \"Maine,\" \"nob shops\" instead of \"no shops,\" and \"bet able\" instead of \"be able\" were apparent from the beginning. Additionally, there were numerous instances of missing letters in words (\"iprofessinal\" instead of \"professional\"), incorrect word forms (\"owf\" instead of \"of\"), and typographical errors that altered the meaning or readability of the text (\"xcan\" instead of \"can,\" \"ea\" instead of \"tea\"). These errors were scattered throughout the document, suggesting a systematic issue with spelling or a deliberate introduction of errors to create a contrast with Document A.\n",
      "\n",
      "The presence of these errors in Document B not only disrupted the flow of reading but also indicated a lack of proofreading or attention to detail that was not evident in Document A. The sheer volume and variety of spelling mistakes in Document B, ranging from simple typographical errors to incorrect word choices, strongly suggested that this document had a significantly higher percentage of words containing errors compared to Document A.\n",
      "\n",
      "Therefore, the document with more spelling errors is: Document B. This conclusion is based on the direct comparison of the two documents, where Document B demonstrated a clear and consistent pattern of spelling and typographical errors throughout the text, unlike Document A, which maintained a high standard of spelling accuracy. \n",
      "Ground truth: 20%, LLM Eval score: After evaluating both documents, I began by scanning each document for obvious spelling errors, noting the types of errors present, such as typographical errors (e.g., missing letters, extra letters, swapped letters), incorrect words, and any misuse of terms that could indicate a spelling mistake. \n",
      "\n",
      "In Document A, I noticed several spelling errors, including \"nob shops\" (likely meant to be \"no shops\"), \"Main\" instead of \"Maine,\" \"bet able\" instead of \"be able,\" \"youve\" missing an apostrophe for \"you've,\" \"wil\" missing an 'l' for \"will,\" \"wha\" missing a 't' for \"what,\" \"botte\" missing a 'l' for \"bottle,\" \"lis\" instead of \"list,\" \"xcan\" which seems to be a typo for \"can,\" \"eso\" instead of \"so,\" \"ipt\" which is unclear but likely a typo, \"comig\" missing an 'n' for \"coming,\" \"thir\" instead of \"their,\" \"caled\" missing an 'l' for \"called,\" \"siz\" missing an 'e' for \"size,\" \"eon\" which is likely a typo, \"thrugh\" missing an 'o' for \"through,\" \"ntebook\" missing an 'o' for \"notebook,\" \"cold fin\" which should be \"could find,\" \"Ij\" which is a typo, \"tof\" likely meant to be \"of,\" \"myx\" which is a typo, \"ixf\" likely a typo, \"Iq\" which is a typo, \"iIt\" which is a typo, \"jof\" which is a typo, \"tyo\" instead of \"to,\" \"toh\" which is likely a typo, \"jojb\" instead of \"job,\" \"toc\" which is likely a typo, \"owf\" instead of \"of,\" \"sese\" instead of \"sense,\" \"onu\" which is likely a typo, \"toh\" again appearing as a typo, \"isb\" instead of \"is,\" \"uso\" likely meant to be \"so,\" \"ibn\" instead of \"in,\" \"au\" which is unclear, \"tox\" instead of \"to,\" \"ore\" instead of \"more,\" \"hahs\" instead of \"has,\" \"forf\" which is likely a typo, and several more throughout the text. \n",
      "\n",
      "Document B also contains numerous spelling errors, including \"206\" instead of \"2006,\" \"riend's huse fon\" instead of \"friend's house on,\" \"sland\" instead of \"island,\" \"pyou\" which is likely a typo, \"thi houe\" instead of \"this house,\" \"cothes anzd toileties\" instead of \"clothes and toiletries,\" \"poin\" missing a 't' for \"point,\" \"addcted\" missing an 'i' for \"addicted,\" \"kif\" which is likely a typo, \"yogu\" instead of \"you,\" \"thins\" missing a 'g' for \"things,\" \"brig\" missing an 'n' for \"bring,\" \"oqf\" which is a typo, \"tbhe\" which is a typo, \"erplugs\" missing an 'a' for \"earplugs,\" \"oaf\" instead of \"of,\" \"theg\" which is a typo, \"ther waso\" instead of \"there was a,\" \"Ic\" which is likely a typo, \"tbhe\" again appearing as a typo, \"ofm\" which is a typo, \"Youg\" instead of \"You,\" \"uare\" which is likely a typo, \"the,\" \"bin\" which is likely a typo, \"cta\" which is a typo, \"harly\" missing a 'd' for \"hardly,\" \"ida\" missing an 'e' for \"idea,\" \"waqy\" which is a typo, \"wik\" instead of \"wick,\" \"otebooks\" missing an 'n' for \"notebooks,\" \"caled\" missing an 'l' for \"called,\" \"ufse\" which is a typo, \"bout\" missing an 'a' for \"about,\" \"tha\" missing an 't' for \"that,\" \"fid\" missing an 'n' for \"find,\" \"ya\" which is likely a typo, \"theu\" which is a typo, \"eran\" instead of \"era,\" \"tI\" which is a typo, \"mI\" which is a typo, \"nly\" missing an 'o' for \"only,\" \"ooks\" missing a 'b' for \"books,\" \"rute\" missing an 'o' for \"route,\" \"ojn\" which is a typo, \"iln\" which is a typo, \"Bxut\" which is a typo, \"mfy\" which is a typo, \"thfe\" which is a typo, \"ble\" missing an 'a' for \"able,\" \"iyf\" which is a typo, \"Ifv\" which is a typo, \"nowt\" instead of \"not,\" \"Tey're\" missing an 'h' for \"They're,\" \"Gcet\" which is a typo, \"sto\" instead of \"to,\" \"ythe\" which is a typo, \"wor\" which is likely a typo, \"msay\" which is a typo, \"wth\" missing an 'i' for \"with,\" \"usi\" missing an 'n' for \"using,\" \"bcor\" which is a typo, \"bgan\" missing an 'i' for \"began,\" \"tor\" which is likely a typo, \"puqt\" which is a typo, \"sese\" instead of \"sense,\" \"ibs\" which is a typo, \"cin\" which is a typo, \"itn\" which is a typo, \"Itl\" which is a typo, \"dfferent\" missing an 'i' for \"different,\" \"zto\" which is a typo, \"itu\" which is a typo, \"hey\" missing a 't' for \"they,\" \"gto\" instead of \"to,\" \"ba\" which is likely a typo, \"two\" instead of \"to,\" \"son\" which is likely a typo, \"yown\" which is a typo, \"uggest\" which is a typo, \"isv\" which is a typo, \"wrk\" missing an 'o' for \"work,\" \"sjo\" which is a typo, \"eto\" which is a typo, \"Bqut\" which is a typo, \"ina\" missing an 'n' for \"in a,\" \"das\" which is a typo, \"cifc\" which is a typo, \"tvhe\" which is a typo, \"tbhe\" which is a typo, \"isy\" which is a typo, \"ini\" missing a 'g' for \"in,\" \"yopu\" which is a typo, \"hat\" missing a 't' for \"that,\" \"thpe\" which is a typo, \"ohas\" which is a typo, \"wit\" missing an 'h' for \"with,\" \"yor\" which is a typo, \"havs\" missing an 'e' for \"haves,\" \"nmber\" missing a 'u' for \"number,\" \"abut\" missing an 'o' for \"about,\" \"hae\" missing a 'v' for \"have,\" and several more throughout the text.\n",
      "\n",
      "Both documents contain a significant number of spelling errors, but Document B appears to have a higher frequency of errors, with almost every sentence containing one or more mistakes. The errors in Document B are also more varied, including missing letters, extra letters, incorrect letters, and completely incorrect words. This suggests a higher level of carelessness or a lower level of proofreading compared to Document A.\n",
      "\n",
      "Therefore, the document with more spelling errors is: Document B. \n",
      "Ground truth: 30%, LLM Eval score: After evaluating both documents, I began by noting the types of errors present in each document, including misspellings, typographical errors, and incorrect or missing spaces between words. Both documents contain a significant number of errors, but the nature and frequency of these errors vary between the two.\n",
      "\n",
      "In Document A, errors are pervasive and include a wide variety of issues such as misspelled words (\"riend's huse\" instead of \"friend's house\"), incorrect letters (\"sland\" instead of \"island\"), and missing letters in words (\"addcted\" instead of \"addicted\"). Additionally, there are instances of letters being replaced with similar-looking numbers or symbols (\"206I\" instead of \"2006\"), which further complicates the text. The errors in Document A are not only frequent but also diverse, affecting the readability of the text significantly.\n",
      "\n",
      "Document B, on the other hand, also contains numerous spelling errors and typographical mistakes. However, upon closer inspection, the errors in Document B, while still impacting readability, seem slightly less diverse in nature. The errors predominantly consist of misspelled words (\"ya\" instead of \"a\", \"qoat\" instead of \"coat\"), and fewer instances of incorrect letters or symbols replacing correct ones. The frequency of errors is high, but the variety of error types is somewhat narrower than in Document A.\n",
      "\n",
      "To determine which document has a higher percentage of spelling errors, I considered both the frequency and the variety of errors. While both documents are riddled with mistakes, Document A's errors are more varied, including a mix of misspellings, incorrect letters, and symbols that do not belong, making it more challenging to read and understand. Document B, while also containing many errors, has them more confined to misspellings and fewer bizarre substitutions (like numbers for letters).\n",
      "\n",
      "Therefore, the document with more spelling errors, considering both the diversity and the impact of these errors on readability, is: Document A. \n",
      "Ground truth: 40%, LLM Eval score: After evaluating both documents, I began by noting the presence of spelling errors throughout both texts. To determine which document has a higher percentage of spelling errors, I considered the following steps in my analysis:\n",
      "\n",
      "1. **Initial Observation**: Both documents contain numerous spelling errors, including misspelled words, incorrect letter insertions, and omitted letters. However, a simple visual inspection is insufficient to determine which has a higher error rate without a more structured approach.\n",
      "\n",
      "2. **Error Types and Frequency**: I noticed that both documents share similar types of errors, such as substitution of letters (e.g., \"ya\" instead of \"you\" in Document A and \"ae\" instead of \"a\" in Document B), omission of letters (e.g., \"wht\" instead of \"what\" in Document A and \"tht\" instead of \"that\" in Document B), and insertion of incorrect letters (e.g., \"hady\" instead of \"handy\" in Document A and \"wekend\" instead of \"weekend\" in Document B). This similarity suggests that the errors may have been introduced deliberately as part of the task design.\n",
      "\n",
      "3. **Quantitative Analysis Approach**: To accurately determine which document has a higher percentage of spelling errors, one would ideally count the total number of errors in each document and divide by the total number of words to get an error rate. However, without executing an exact count and given the task's constraints, I must rely on a qualitative assessment.\n",
      "\n",
      "4. **Qualitative Assessment**: By comparing sections of similar length from both documents, it appears that Document A has a slightly higher density of errors. This observation is based on the frequency of errors encountered in a given amount of text. For example, the introduction in Document A seems to have more errors per sentence compared to the same section in Document B.\n",
      "\n",
      "5. **Error Impact on Readability**: Both documents are impacted by the spelling errors, but Document A's readability seems more adversely affected. The errors in Document A frequently disrupt the flow of reading to a greater extent than those in Document B, suggesting a higher error rate.\n",
      "\n",
      "Therefore, based on the qualitative assessment of the error types, frequency, and their impact on readability, the document with more spelling errors is: Document A. This conclusion is drawn from the observation that Document A appears to have a higher density of errors in the text examined, affecting its readability more significantly than the errors in Document B. \n",
      "Ground truth: 50%, LLM Eval score: After evaluating both documents, I began by noting the presence of spelling errors in each document. To systematically approach this task, I divided my analysis into several steps:\n",
      "\n",
      "1. **Initial Observation**: Both documents contain numerous spelling errors, including misspelled words, incorrect letter insertions, and omitted letters. However, a cursory glance does not suffice to determine which document has a higher percentage of errors.\n",
      "\n",
      "2. **Error Types Identification**: I identified several types of errors, such as substitution errors (e.g., \"ae\" instead of \"a\" in Document A), insertion errors (extra letters added), deletion errors (missing letters), and transposition errors (letters swapped). Both documents exhibit these errors, but quantifying them requires a closer look.\n",
      "\n",
      "3. **Sample Analysis**: Taking a small sample from each document and analyzing the error rate could provide insight. For instance, the first paragraph of each document shows that Document A has a higher frequency of errors per sentence than Document B. This method, while not exhaustive, gives an initial indication of which document might have more errors overall.\n",
      "\n",
      "4. **Error Density**: Considering the length of each document and the distribution of errors, it's important to assess not just the total number of errors but the density of errors (errors per sentence or per paragraph). This step requires a more detailed examination but is crucial for accuracy.\n",
      "\n",
      "5. **Contextual Errors**: Beyond spelling, there are contextual errors to consider, such as incorrect word usage that might not be caught by a simple spell check. This analysis is more nuanced and requires understanding the intended meaning of each sentence.\n",
      "\n",
      "6. **Comparative Analysis**: By comparing similar sections from each document, I can gauge which one consistently shows a higher error rate. This involves looking at equivalent paragraphs and assessing the number and types of errors present.\n",
      "\n",
      "Based on these steps, my analysis leans towards Document A having a higher percentage of spelling errors. The errors in Document A seem more frequent and varied, including numerous instances of incorrect letters and misspelled words that significantly disrupt the readability. Document B, while also containing a substantial number of errors, appears slightly more coherent with fewer disruptions per sentence on average.\n",
      "\n",
      "Therefore, the document with more spelling errors is: Document A. \n",
      "Ground truth: 60%, LLM Eval score: After evaluating both documents, I began by noting the presence of spelling errors in each document. To systematically approach this task, I considered the following steps:\n",
      "\n",
      "1. **Identifying Errors**: I scanned through both documents to identify obvious spelling errors. Both documents contain numerous spelling mistakes, but a detailed count or identification of every single error is beyond the scope of this analysis without automated tools. However, a cursory glance shows that both documents are riddled with errors.\n",
      "\n",
      "2. **Error Types**: The errors range from missing letters, additional letters, transposed letters, and completely incorrect words. Both documents exhibit a similar variety of error types, suggesting that the errors were introduced deliberately for the purpose of this task.\n",
      "\n",
      "3. **Error Density**: Given the similarity in types of errors, the deciding factor comes down to the density of errors - essentially, whether Document A or Document B has a higher frequency of errors relative to the total word count. While an exact count is not feasible without processing the text programmatically, a qualitative assessment suggests that both documents have a high density of errors. However, Document B seems to have slightly more consistent errors throughout, with almost every sentence containing multiple errors.\n",
      "\n",
      "4. **Length and Structure**: Both documents are of a similar length and structure, discussing personal anecdotes and reflections. This similarity means that the deciding factor really does come down to the sheer number of errors rather than differences in length or complexity that might otherwise skew the error percentage.\n",
      "\n",
      "5. **Subjective Assessment**: Given the limitations of a manual, non-quantitative analysis, my assessment must be somewhat subjective. However, by focusing on sections of text and comparing the frequency of errors in those sections across both documents, Document B appears to have a marginally higher error rate. This observation is based on the consistent presence of errors in nearly every word or phrase in Document B, as opposed to Document A, which, while also highly error-ridden, has a few more stretches of correct or nearly correct text.\n",
      "\n",
      "Therefore, the document with more spelling errors is: Document B.\n",
      "\n",
      "This conclusion is drawn from a qualitative assessment of the error density and the subjective observation that Document B seems to have a slightly higher frequency of errors throughout its text. Without a quantitative, word-by-word analysis, this conclusion is the best approximation based on the available evidence and the methodology described. \n",
      "Ground truth: 70%, LLM Eval score: After evaluating both documents, I began by noting the presence of spelling errors in each document. To systematically approach this task, I considered the following steps:\n",
      "\n",
      "1. **Initial Observation**: A cursory glance at both documents reveals numerous spelling errors, including misspelled words, incorrect letter substitutions, and nonsensical sequences of characters that do not form coherent words.\n",
      "\n",
      "2. **Error Types and Frequency**: Both documents contain various types of spelling errors, but the nature and frequency of these errors seem to differ. Document A exhibits a higher frequency of errors involving incorrect letter substitutions (e.g., \"206I\" instead of \"2061\", \"hand\" instead of \"and\") and the addition of extraneous characters within words. Document B also has spelling errors, including letter substitutions and missing letters, but the errors appear slightly less chaotic in nature.\n",
      "\n",
      "3. **Consistency Across Documents**: Both documents share a similar structure and content, suggesting they are different versions of the same text. This similarity allows for a direct comparison of error types and frequencies in corresponding sections.\n",
      "\n",
      "4. **Quantitative vs. Qualitative Analysis**: While a precise, quantitative count of errors in each document would be ideal, the task's constraints necessitate a qualitative assessment based on the observed frequency and severity of errors.\n",
      "\n",
      "5. **Severity of Errors**: Some errors disrupt readability more significantly than others. In Document A, the errors often render sentences difficult to understand without careful reading. Document B, while also containing numerous errors, seems slightly more coherent at a glance.\n",
      "\n",
      "Based on these considerations, Document A appears to have a higher frequency of spelling errors and a greater severity of errors that impact readability more significantly than those in Document B. The errors in Document A are more disruptive, often making it challenging to discern the intended words or meaning without additional context or effort.\n",
      "\n",
      "Therefore, the document with more spelling errors is: Document A. \n",
      "Ground truth: 80%, LLM Eval score: After evaluating both documents, I began by noting the presence of spelling errors in both texts. To systematically approach the task, I considered several factors:\n",
      "\n",
      "1. **Frequency of Errors**: Both documents contain numerous spelling errors, including misspelled words, incorrect letter substitutions, and missing or extra letters in words. However, a cursory glance suggests that Document A has a slightly higher frequency of these errors.\n",
      "\n",
      "2. **Types of Errors**: Both documents exhibit similar types of errors, such as substitution (e.g., \"uly\" instead of \"July\" in Document A and \"Jly\" in Document B), omission (missing letters or spaces), and insertion (extra letters or incorrect spaces). The complexity and variety of errors are comparable in both documents.\n",
      "\n",
      "3. **Length and Density of Text**: Both documents are of similar length, which means that a simple count of errors could potentially give a good indication of which document has a higher error rate. However, without an exact word count, this factor alone cannot determine the outcome.\n",
      "\n",
      "4. **Consistency of Errors**: Document A seems to have a slightly higher consistency in the types of errors, with more frequent occurrences of unusual substitutions and omissions. Document B, while also containing many errors, has them spread out in a manner that seems slightly less dense upon visual inspection.\n",
      "\n",
      "5. **Impact on Readability**: Both documents are significantly impacted in terms of readability due to the spelling errors. However, the decision should be based on the frequency and density of errors rather than the impact on readability.\n",
      "\n",
      "Given these considerations, the task is to determine which document has a higher percentage of words containing errors. While both documents are riddled with spelling mistakes, Document A appears to have a marginally higher frequency and variety of errors throughout the text. This observation is based on the initial visual inspection and the noted consistency of errors, which seem to be slightly more pervasive in Document A.\n",
      "\n",
      "Therefore, the document with more spelling errors is: Document A. \n",
      "Ground truth: 90%, LLM Eval score: After evaluating both documents, I began by noting the obvious spelling errors in each document. Document A and Document B both contain numerous spelling errors, but to accurately determine which has a higher percentage of errors, I considered the length of each document and the density of errors within that length.\n",
      "\n",
      "In Document A, errors are immediately noticeable and consistent throughout the text. Words are misspelled, letters are missing, and there are instances of incorrect letter substitutions. For example, \"Jly\" instead of \"July,\" \"discvered\" instead of \"discovered,\" and \"andy\" instead of \"handy.\" These errors are not isolated but rather form a pattern that persists from the beginning to the end of the document.\n",
      "\n",
      "Document B also contains a significant number of spelling errors. Similar to Document A, there are misspellings, missing letters, and incorrect substitutions, such as \"dscovered\" for \"discovered,\" \"hndy\" for \"handy,\" and \"est\" for \"test.\" The errors in Document B mirror the types of errors seen in Document A, suggesting a similar level of carelessness or error in typing.\n",
      "\n",
      "To determine which document has a higher percentage of errors, I considered the overall coherence and readability of each document despite the errors. Both documents are challenging to read, but Document A seems to have a slightly higher density of errors, affecting more words in each sentence on average. This observation is subjective but is based on the consistent presence of errors in nearly every word or phrase in Document A, which slightly outpaces the frequency and impact of errors in Document B.\n",
      "\n",
      "Therefore, the document with more spelling errors is: Document A. This conclusion is drawn from the observed density and impact of spelling errors throughout the text, which suggests that a higher percentage of words in Document A are affected by spelling errors compared to Document B. \n",
      "Ground truth: 100%, LLM Eval score: After evaluating both documents, it's clear that both Document A and Document B contain a significant number of spelling errors. To determine which document has a higher percentage of spelling errors, I will outline my thought process step by step:\n",
      "\n",
      "1. **Initial Observation**: Both documents are intended to be the same text with variations in spelling errors. This means that the length of the documents should be roughly the same, making a direct comparison of the number of errors a valid approach to determining which has a higher error rate.\n",
      "\n",
      "2. **Error Identification**: The spelling errors range from missing letters, additional letters, swapped letters, and completely incorrect words. Both documents also contain intentional misspellings to mimic speech or informal writing styles, which should not be counted as errors for this comparison.\n",
      "\n",
      "3. **Error Counting Strategy**: Given the length and complexity of the texts, manually counting each error would be impractical within a short timeframe. However, by examining several paragraphs from each document, I can estimate the density of errors.\n",
      "\n",
      "4. **Sample Analysis**: In the first few lines of both documents, Document A appears to have more instances where letters are swapped, added, or missing. For example, \"206I've\" should be \"2006 I've\", \"dscovered\" should be \"discovered\", and \"ua\" should be \"a\". Document B, while also containing errors, seems slightly more coherent with fewer errors in the same span of text, e.g., \"Juy 2006've\" should be \"July 2006 I've\", \"discoveed\" should be \"discovered\".\n",
      "\n",
      "5. **Consistency Across Documents**: Scanning through the rest of the documents, this pattern holds relatively consistent. Document A consistently shows a higher density of errors per sentence than Document B.\n",
      "\n",
      "6. **Error Types**: Both documents contain similar types of errors, but the frequency and impact on readability are greater in Document A. Document A's errors more severely disrupt the intended meaning of the sentences.\n",
      "\n",
      "7. **Conclusion Rationale**: Based on the observed density and severity of spelling errors, Document A has a higher percentage of words containing errors. The errors in Document A are more frequent and often more jarring, leading to greater difficulty in understanding the text.\n",
      "\n",
      "Therefore, the document with more spelling errors is: Document A. \n"
     ]
    }
   ],
   "source": [
    "if os.path.exists(results_path):\n",
    "    with open(results_path, 'r') as file:\n",
    "        results_dict = json.load(file)\n",
    "else:\n",
    "    results_dict = {}\n",
    "\n",
    "# avoid overwriting previous results\n",
    "if model_name in results_dict and scoring_template in results_dict[model_name]:\n",
    "    print(f\"Results for model '{model_name}' with scoring template '{scoring_template}' already exist.\")\n",
    "    if input(\"Press Enter to continue or type 'exit' to stop: \").strip().lower() == 'exit':\n",
    "        assert(False)\n",
    "\n",
    "print(f\"Running misspelling eval for {model_name}\")\n",
    "\n",
    "results = []\n",
    "# evaluation loop\n",
    "for i in range(1, len(misspelled_contexts)):\n",
    "    ctx_1 = misspelled_contexts[i-1]\n",
    "    ctx_2 = misspelled_contexts[i]\n",
    "    prompt = templates[prompt_template][scoring_template].format(text_a=ctx_1, text_b=ctx_2)\n",
    "\n",
    "    if local:\n",
    "        input = tokenizer(prompt, return_tensors='pt').input_ids.to(device)\n",
    "        response = local.generate(inputs = input,\n",
    "                                    max_new_tokens=100, \n",
    "                                    pad_token_id = tokenizer.pad_token_id,\n",
    "                                    eos_token_id = tokenizer.eos_token_id)\n",
    "        response = tokenizer.decode(response[0, input.shape[1]:], skip_special_tokens=True)\n",
    "    else:\n",
    "        response = api.invoke(prompt).content\n",
    "\n",
    "    results.append(response)\n",
    "\n",
    "    # save results\n",
    "    if model_name not in results_dict:\n",
    "        results_dict[model_name] = {}\n",
    "\n",
    "    if scoring_template not in results_dict[model_name]:\n",
    "        results_dict[model_name][scoring_template] = []\n",
    "\n",
    "    results_dict[model_name][scoring_template].append({\n",
    "        'misspelled_percentage_a': round(ratios[i-1]*100),\n",
    "        'misspelled_percentage_b': round(ratios[i]*100),\n",
    "        'response': response\n",
    "    })\n",
    "\n",
    "    print(f\"Ground truth: {round(ratios[i]*100)}%, LLM Eval score: {response} \")\n",
    "\n",
    "with open(results_path, 'w') as file:\n",
    "    json.dump(results_dict, file, indent=4)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
